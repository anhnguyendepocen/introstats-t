---
title: 'chapter 7 Probability Axioms'
output:
  tufte::tufte_html:
    tufte_features: ['fonts','background']
    toc: true
    toc_depth: 2
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = FALSE)
library(tidyverse)
library(ggplot2)
library(knitr)
library(kableExtra)
library(extraDistr)
library(gridExtra)
library(latex2exp)
library(moments)
library(bookdown)
library(rsconnect)
library(tufte)
```

```{r, include=FALSE}
paygap <- read.csv('./data/gender-paygap-2019.csv')
paygap <- paygap %>%
  mutate(EmployerSize = factor(EmployerSize, levels = c('0-249','250-499','500-999','1000-4999','5000-19999','20000+')))
nycheat <- read.csv('./data/nyc-heatwave.csv')
```

\newcommand{\E}{\text{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\SD}{\text{SD}}
\newcommand{\SE}{\text{SE}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Cor}{\text{Cor}}
\renewcommand{\P}{\text{P}}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\sumin}{\sum_i^n}
\newcommand{\Bias}{\text{Bias}}

A brief detour into probability. 

```
need better segue into this chapter; feels abrupt
maybe: start with idea of random processes, outcomes, frequentist probability
```

---

# Probability spaces

A **probability space** ($\Omega$, $\mathcal F$, $P$) has three parts:

* $\Omega$, a **sample space**, which is the set of all possible outcomes (all combinations of atomic elements)
    + e.g. if you toss a coin twice: $\Omega = \{ HH, HT, TH, TT \}$  
* $\mathcal F$, a **set of events**, that make up all possible subsets of the sample space
    + e.g. $\mathcal F = \{ \text{getting 1 head, getting 2 heads, ...} \}$
* $P$, a **probability function**, that assigns probabilities to each event
    + e.g. the probability of getting 2 heads: $P(\text{ 2 heads }) = \frac 14$ 
    
Probability spaces are used to model random processes.   

\ 

---

# Conditional probability

Given two events, $A$ and $B$ (both from the set of events $\mathcal F$), the probability that $A$ occurs given that $B$ has already occurred is:

$$\boxed{ P(A|B) = \frac{P(A \cap B)}{P(B)} }$$

where:

* $P(A|B)$ is the conditional probability of $A$ given $B$
* $P(A \cap B)$ is the probability that both $A$ and $B$ occur
* $P(B)$ is the probability that $B$ occurs

Note this theorem is a postulate, not a theoretical result. The RHS of the equation can be interpreted as restricting the sample space of $A$ and $B$ to only those outcomes where $B$ occurs.  

Rearranging gives the **multiplication rule:**

$$\boxed { P(A \cap B) = P(A|B) \; P(B) }$$

\ 

---

# Independence

Two events are independent if the occurrence of one has no effect on the probability the other occurs.  

If events $A$ and $B$ are independent:

$$\boxed { P(A|B) = P(A) } \hspace{0.5cm} \text{(indep.)}$$

i.e. the probability of that $A$ occurs is invariant to whether $B$ has occurred or not.  

Thus the multiplication rule for independent events can be written as: 

$$\boxed{ P(A \cap B) = P(A) \; P(B) } \hspace{0.5cm} \text{(indep.)}$$

\ 

---

# Mutual exclusivity

Events are mutually exclusive or **disjoint** if they cannot both happen.  

E.g. if event $A$ occurs, then event $B$ cannot also happen if they are mutually exclusive.  

This leads to the **addition rule:** for two mutually exclusive events $A$ and $B$, the probability that at least one will happen:  

$$\boxed { P(A \cup B) = P(A) + P(B) } \hspace{0.5cm} \text{(mutually excl.)}$$

\ 

---

# Law of total probability

Given two events, $A$ and $B$, the probability that $A$ occurs can be written:

$$P(A) = P(A \cap B) + P(A \cap B')$$
Using the definition of conditional probability, $P(A \cap B) = P(A|B)P(B)$, you can also write: 

$$P(A) = P(A|B)P(B) + P(A|B')P(B')$$
More generally: if your event space contains $A$ and multiple other events, e.g. $\mathcal F = \{A, B_1, B_2, ..., B_n \}$. Then:

$$\boxed{ P(A) = \sum_i P(A \cap B_i) = \sum_i P(A|B_i)P(B_i) }$$

\ 

---

# Simple combinatorics  

`this section needs some work`

You toss a coin twice. The outcomes are $\Omega = \{ HH, HT, TH, TT \}$.  

What is the probability of getting 2 heads? You know that 1/4 outcomes correspond to this event, so the probability is simply $\frac 14$. 

Some terminology: the number of outcomes corresponding to an event is called the **multiplicity** of the event. 

To calculate the probability of an event, you divide the multiplicity of the event (a restricted sample space) by the multiplicity of the whole sample space: 

$$P(\text{2 heads}) = \frac{\Omega(\text{2 heads})}{\Omega(\text{all})} = \frac 14 $$
Finding the multiplicity of an event is easy when the sample space is small (in a 2-coin set, there is only 1 way of arranging 2 heads).  

But say you toss the coin 100 times. Now what is the probability of getting 2 heads? You need to know how many ways you can get 2 heads in a 100-coin set. There are 100 choices for the first coin, and 99 remaining choices for the second coin. And since you can choose any pair in either order, the number of distinct pairs is:

$$\Omega(\text{2 heads, 100-coin set}) = \frac{100 \cdot 99}{2} = 4950$$
The total number of ways to arrange 100 coins is $2^{100}$ (each coin has two states, and there are 100 coins). Thus the probability of getting 2 heads in a 100-coin set:

$$P(\text{2 heads, 100-coin set}) = \frac{\Omega(\text{2 heads, 100-coin set})}{\Omega(\text{100 coins})} = \frac{4950}{2^{100}} = ...$$
What about the probability of getting 3 heads? There are 100 choices for the first coin, 99 for the second, and 98 for the third. And for each triplet, there are 3 choices on which one to flip first, and for each of these 2 choices on which to flip second. Thus the number of distinct triplets is:  

$$\Omega(\text{3 heads, 100-coin set}) = \frac{100 \cdot 99 \cdot 98}{3 \cdot 2} = 161700$$
Hopefully you can see the pattern here. The number of ways to get $k$ coins in a 100 coin set is:

$$\Omega(k \text{ coins, 100-coin set}) = \frac{100 \cdot 99 ... (100 - k + 1)}{k!} = \frac{100!}{k! \; (100-k)!}$$
If you have $n$ coins, the number of ways you can get $k$ heads is:

$$\Omega(n,k) = \frac{n!}{k! \; (n-k)!} = \begin{pmatrix} n \\ k\end{pmatrix}$$
This is known as the **binomial coefficient**. It gives the number ways of choosing $k$ elements from an $n$-element set ($n$ choose $k$).  






